{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7b3d6d8",
   "metadata": {},
   "source": [
    "# Inference with a trainined YOLOv5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b18a3922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Root directory\n",
    "root_dir = '/Users/Holmes/Research/Projects/vespalert'\n",
    "sys.path.insert(0, root_dir)\n",
    "os.chdir(os.path.join(root_dir, 'models/yolov5'))  # Move to yolov5\n",
    "\n",
    "# Automatically reload imported programmes\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adca3b6",
   "metadata": {},
   "source": [
    "## Image inference\n",
    "We utilise `detect.py` from YOLOv5.\n",
    "- The `--source` flag allows one to choose the input source: single image; folder of images; video; webcam.\n",
    "- The `--conf` flag sets the threshold for object confidence.\n",
    "- The `--name` flag located where the detections are stored within `yolov5/runs/detect/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "890c26d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['../yolov5-runs/train/smallnet/weights/best.pt'], source=../../datasets/queen.jpg, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../yolov5-runs/detect, name=queenie, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
      "YOLOv5 ðŸš€ 2022-6-1 Python-3.9.10 torch-1.10.2 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "image 1/1 /Users/Holmes/Research/Projects/vespalert/datasets/queen.jpg: 384x640 1 Vespa crabro, Done. (0.178s)\n",
      "Speed: 1.0ms pre-process, 177.6ms inference, 1.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1m../yolov5-runs/detect/queenie\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# To print detections over folder with chosen confidence `--conf` (x3)\n",
    "!python detect.py   --conf 0.50 \\\n",
    "                    --source ../../datasets/queen.jpg \\\n",
    "                    --weights ../yolov5-runs/train/smallnet/weights/best.pt \\\n",
    "                    --project ../yolov5-runs/detect \\\n",
    "                    --name queenie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2032915c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
